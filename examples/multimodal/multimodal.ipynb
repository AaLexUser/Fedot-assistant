{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81294e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.core.utils.loaders import load_zip\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"pkg_resources\")\n",
    "\n",
    "\n",
    "download_dir = \"./competition\"\n",
    "zip_file = (\n",
    "    \"https://drive.google.com/uc?export=download&id=1pZnoEkMGbFy1pyQnIbCa9lT4DgZ5AG4Z\"\n",
    ")\n",
    "\n",
    "load_zip.unzip(zip_file, unzip_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a0b844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting FedotLLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,770 - Starting FedotLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Presets: medium_quality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,770 - Presets: medium_quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading default config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/default.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,771 - Loading default config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/default.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merging medium_quality config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/medium_quality.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,776 - Merging medium_quality config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/medium_quality.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,778 - Successfully loaded config\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ¤– <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Welcome to FEDOT.LLM </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ¤– \u001b[1;31m Welcome to FEDOT.LLM \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Will use task config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Will use task config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'infer_eval_metric'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'detect_and_drop_id_column'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'task_preprocessors_timeout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3600</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_limit'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_artifacts'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'append_timestamp'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'./artifacts'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_transformers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enabled_models'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'CAAFE'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fedotllm.transformer.feature_transformers.caafe.CAAFETransformer'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lightgdm'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${llm.provider}'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'llm_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${llm.model}'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'num_iterations'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'optimization_metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'roc'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'automl'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'autogluon'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'autogluon'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'predictor_init_kwargs'</span>: <span style=\"font-weight: bold\">{}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'predictor_fit_kwargs'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'presets'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'medium_quality'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'fedot'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'predictor_init_kwargs'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'preset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fast_train'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'predictor_fit_kwargs'</span>: <span style=\"font-weight: bold\">{}}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'base_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://models.inference.ai.azure.com'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${env:FEDOTLLM_LLM_API_KEY}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'infer_eval_metric'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'detect_and_drop_id_column'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'task_preprocessors_timeout'\u001b[0m: \u001b[1;36m3600\u001b[0m,\n",
       "    \u001b[32m'time_limit'\u001b[0m: \u001b[1;36m600\u001b[0m,\n",
       "    \u001b[32m'save_artifacts'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'append_timestamp'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'./artifacts'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'feature_transformers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enabled_models'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'models'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'CAAFE'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'_target_'\u001b[0m: \u001b[32m'fedotllm.transformer.feature_transformers.caafe.CAAFETransformer'\u001b[0m,\n",
       "                \u001b[32m'eval_model'\u001b[0m: \u001b[32m'lightgdm'\u001b[0m,\n",
       "                \u001b[32m'llm_provider'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mllm.provider\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'llm_model'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mllm.model\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'num_iterations'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "                \u001b[32m'optimization_metric'\u001b[0m: \u001b[32m'roc'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'automl'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enabled'\u001b[0m: \u001b[32m'autogluon'\u001b[0m,\n",
       "        \u001b[32m'autogluon'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'predictor_init_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'predictor_fit_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'presets'\u001b[0m: \u001b[32m'medium_quality'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'fedot'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'predictor_init_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'preset'\u001b[0m: \u001b[32m'fast_train'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'predictor_fit_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'llm'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "        \u001b[32m'base_url'\u001b[0m: \u001b[32m'https://models.inference.ai.azure.com'\u001b[0m,\n",
       "        \u001b[32m'api_key'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32menv:FEDOTLLM_LLM_API_KEY\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[32m'verbose'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">petfinder_for_tutorial</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task path: \u001b[35m/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/\u001b[0m\u001b[95mpetfinder_for_tutorial\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Task loaded!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTask loaded!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TabularPredictionTask</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">petfinder_for_tutorial</span>, <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> datasets<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTabularPredictionTask\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[35mpetfinder_for_tutorial\u001b[0m, \u001b[33mdescription\u001b[0m=, \u001b[1;36m4\u001b[0m datasets\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.llm.llm:FedotLLM is using model gpt-4o-mini to assist you with the task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,788 - FedotLLM is using model gpt-4o-mini to assist you with the task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 0.04 seconds initializing components. Time remaining: 599.95/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,818 - It took 0.04 seconds initializing components. Time remaining: 599.95/600.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Task understanding starts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:46,819 - Task understanding starts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mdata_description_file\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/descriptions.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:48,795 - \u001b[1mdata_description_file\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/descriptions.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mdescription\u001b[0m: data_description_file: Multimodal The goal is to predict pet adoption rates based on their adoption profiles. In this simplified version, the adoption speed is grouped into two categories: 0 (slow) and 1 (fast). \\n\\nTarget Variable:\\n- AdoptionSpeed\\n\\nEach animalâ€™s adoption profile includes pictures, a text description, and various tabular features such as age, breed, name, color, and more. Letâ€™s look at a picture and description for an example row of data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:48,797 - \u001b[1mdescription\u001b[0m: data_description_file: Multimodal The goal is to predict pet adoption rates based on their adoption profiles. In this simplified version, the adoption speed is grouped into two categories: 0 (slow) and 1 (fast). \\n\\nTarget Variable:\\n- AdoptionSpeed\\n\\nEach animalâ€™s adoption profile includes pictures, a text description, and various tabular features such as age, breed, name, color, and more. Letâ€™s look at a picture and description for an example row of data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtrain_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:52,556 - \u001b[1mtrain_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtest_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:52,569 - \u001b[1mtest_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1msample_submission_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/sample_submission.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:52,573 - \u001b[1msample_submission_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/sample_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mlabel_column\u001b[0m: AdoptionSpeed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:53,519 - \u001b[1mlabel_column\u001b[0m: AdoptionSpeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtask_type\u001b[0m: multimodal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:54,344 - \u001b[1mtask_type\u001b[0m: multimodal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mproblem_type\u001b[0m: binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,036 - \u001b[1mproblem_type\u001b[0m: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1meval_metric\u001b[0m: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,859 - \u001b[1meval_metric\u001b[0m: f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:\u001b[1mTotal number of prompt tokens:\u001b[0m 1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,861 - \u001b[1mTotal number of prompt tokens:\u001b[0m 1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:\u001b[1mTotal number of completion tokens:\u001b[0m 207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,863 - \u001b[1mTotal number of completion tokens:\u001b[0m 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Task understanding complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,864 - Task understanding complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Automatic feature generation is disabled or not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,866 - Automatic feature generation is disabled or not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 9.05 seconds preprocessing task. Time remaining: 590.90/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,868 - It took 9.05 seconds preprocessing task. Time remaining: 590.90/600.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model training starts<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model training starts\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.autogluon:Fitting AutoGluon MultiModalPredictor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,870 - Fitting AutoGluon MultiModalPredictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.autogluon:predictor_init_kwargs: {'label': 'AdoptionSpeed', 'problem_type': 'binary', 'eval_metric': 'f1'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,871 - predictor_init_kwargs: {'label': 'AdoptionSpeed', 'problem_type': 'binary', 'eval_metric': 'f1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.autogluon:predictor_fit_kwargs: {'presets': 'medium_quality'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:21:55,872 - predictor_fit_kwargs: {'presets': 'medium_quality'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250603_122156\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.10.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.5.0: Tue Apr 22 19:54:25 PDT 2025; root:xnu-11417.121.6~2/RELEASE_ARM64_T6020\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.6.0\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       13.02 GB / 32.00 GB (40.7%)\n",
      "Disk Space Avail:   104.81 GB / 926.35 GB (11.3%)\n",
      "===================================================\n",
      "\n",
      "AutoMM starts to create your model. âœ¨âœ¨âœ¨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156\n",
      "    ```\n",
      "\n",
      "INFO: Seed set to 0\n",
      "GPU Count: 0\n",
      "GPU Count to be Used: 0\n",
      "\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 14.5 M | train\n",
      "1 | validation_metric | BinaryF1Score       | 0      | train\n",
      "2 | loss_func         | CrossEntropyLoss    | 0      | train\n",
      "------------------------------------------------------------------\n",
      "14.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.5 M    Total params\n",
      "58.134    Total estimated model params size (MB)\n",
      "310       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bc5f664ae940f5ae7f6d2cb44eefb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b337516bb664d2d9b23abb800b28c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc87e2cf7cc4120994ee795b27ba0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 1: 'val_f1' reached 0.66667 (best 0.66667), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=0-step=1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15e22ba5f6546b0a2b2e107f7e7082b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 4: 'val_f1' reached 0.00000 (best 0.66667), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=0-step=4.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2d07a0259643d88d6ab66602afdf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 1, global step 5: 'val_f1' reached 0.62385 (best 0.66667), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=1-step=5.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d188f21a6f3430bb69cd47c64217c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 1, global step 8: 'val_f1' reached 0.74534 (best 0.74534), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=1-step=8.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6447317d838e41e49db19d020153f7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 2, global step 9: 'val_f1' reached 0.95726 (best 0.95726), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=2-step=9.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38e2d33c19d4ce990f939f9b0bced19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 2, global step 12: 'val_f1' reached 0.98305 (best 0.98305), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=2-step=12.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9345981990fe4340b0278abf953101e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 3, global step 13: 'val_f1' reached 0.93023 (best 0.98305), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=3-step=13.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986c30ecf2484b02a89dec5f0b12d5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 3, global step 16: 'val_f1' reached 0.99160 (best 0.99160), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=3-step=16.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a5ec474c2440f8948931406cc6a9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 4, global step 17: 'val_f1' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5650f9aa691e41f5810b00291b81c2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 4, global step 20: 'val_f1' reached 1.00000 (best 1.00000), saving model to '/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156/epoch=4-step=20.ckpt' as top 3\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c8cda33cc146d4b57fa4af166045be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9553ffce785f45d0b7151365bef1c180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdcf9ce90104fbe93a5c872cc283df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/AutogluonModels/ag-20250603_122156\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Model training complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mModel training complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 194.90 seconds training model. Time remaining: 396.00/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:25:10,770 - It took 194.90 seconds training model. Time remaining: 396.00/600.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prediction starts<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prediction starts\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/autogluon/multimodal/data/templates.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e326dc0219449bab85fdf3c4ba6b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming: The following columns are not in predictions and will be treated as ID columns:['Id']\n",
      "Warming: Copied from test data for column 'Id'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Prediction complete! Outputs written to fedotllm-20250603_152537.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m Prediction complete! Outputs written to fedotllm-20250603_152537.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 26.38 seconds making predictions. Time remaining: 369.62/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:25:37,150 - It took 26.38 seconds making predictions. Time remaining: 369.62/600.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fedotllm-20250603_152537.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedotllm import run_assistant\n",
    "\n",
    "run_assistant(\"./competition/petfinder_for_tutorial\", presets=\"medium_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63fcd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting FedotLLM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,680 - Starting FedotLLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Presets: medium_quality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,682 - Presets: medium_quality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading default config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/default.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,683 - Loading default config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/default.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Merging medium_quality config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/medium_quality.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,688 - Merging medium_quality config from: /Users/aleksejlapin/Work/NEWFedotLLM/fedotllm/configs/medium_quality.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Applying command-line overrides: [\"automl.enabled='fedot'\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,691 - Applying command-line overrides: [\"automl.enabled='fedot'\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully applied command-line overrides\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,693 - Successfully applied command-line overrides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully loaded config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,694 - Successfully loaded config\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ¤– <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Welcome to FEDOT.LLM </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ¤– \u001b[1;31m Welcome to FEDOT.LLM \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Will use task config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Will use task config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'infer_eval_metric'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'detect_and_drop_id_column'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'task_preprocessors_timeout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3600</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'time_limit'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'save_artifacts'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'append_timestamp'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'./artifacts'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_transformers'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enabled_models'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'models'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'CAAFE'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fedotllm.transformer.feature_transformers.caafe.CAAFETransformer'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lightgdm'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'llm_provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${llm.provider}'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'llm_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${llm.model}'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'num_iterations'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'optimization_metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'roc'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'automl'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fedot'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'autogluon'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'predictor_init_kwargs'</span>: <span style=\"font-weight: bold\">{}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'predictor_fit_kwargs'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'presets'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'medium_quality'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'fedot'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'predictor_init_kwargs'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'preset'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fast_train'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'predictor_fit_kwargs'</span>: <span style=\"font-weight: bold\">{}}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'provider'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'openai'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'base_url'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://models.inference.ai.azure.com'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${env:FEDOTLLM_LLM_API_KEY}'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'verbose'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'infer_eval_metric'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'detect_and_drop_id_column'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[32m'task_preprocessors_timeout'\u001b[0m: \u001b[1;36m3600\u001b[0m,\n",
       "    \u001b[32m'time_limit'\u001b[0m: \u001b[1;36m600\u001b[0m,\n",
       "    \u001b[32m'save_artifacts'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'append_timestamp'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'path'\u001b[0m: \u001b[32m'./artifacts'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'feature_transformers'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enabled_models'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'models'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'CAAFE'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'_target_'\u001b[0m: \u001b[32m'fedotllm.transformer.feature_transformers.caafe.CAAFETransformer'\u001b[0m,\n",
       "                \u001b[32m'eval_model'\u001b[0m: \u001b[32m'lightgdm'\u001b[0m,\n",
       "                \u001b[32m'llm_provider'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mllm.provider\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'llm_model'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mllm.model\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'num_iterations'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
       "                \u001b[32m'optimization_metric'\u001b[0m: \u001b[32m'roc'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'automl'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enabled'\u001b[0m: \u001b[32m'fedot'\u001b[0m,\n",
       "        \u001b[32m'autogluon'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'predictor_init_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'predictor_fit_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'presets'\u001b[0m: \u001b[32m'medium_quality'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'fedot'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'predictor_init_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'preset'\u001b[0m: \u001b[32m'fast_train'\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'predictor_fit_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'llm'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
       "        \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini'\u001b[0m,\n",
       "        \u001b[32m'base_url'\u001b[0m: \u001b[32m'https://models.inference.ai.azure.com'\u001b[0m,\n",
       "        \u001b[32m'api_key'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32menv:FEDOTLLM_LLM_API_KEY\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "        \u001b[32m'verbose'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Task path: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">petfinder_for_tutorial</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Task path: \u001b[35m/Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/\u001b[0m\u001b[95mpetfinder_for_tutorial\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Task loaded!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mTask loaded!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TabularPredictionTask</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">petfinder_for_tutorial</span>, <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> datasets<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTabularPredictionTask\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[35mpetfinder_for_tutorial\u001b[0m, \u001b[33mdescription\u001b[0m=, \u001b[1;36m4\u001b[0m datasets\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.llm.llm:FedotLLM is using model gpt-4o-mini to assist you with the task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,712 - FedotLLM is using model gpt-4o-mini to assist you with the task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 0.06 seconds initializing components. Time remaining: 599.93/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,753 - It took 0.06 seconds initializing components. Time remaining: 599.93/600.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Task understanding starts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:24,754 - Task understanding starts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mdata_description_file\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/descriptions.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:27,108 - \u001b[1mdata_description_file\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/descriptions.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mdescription\u001b[0m: data_description_file: Multimodal The goal is to predict pet adoption rates based on their adoption profiles. In this simplified version, the adoption speed is grouped into two categories: 0 (slow) and 1 (fast). \\n\\nTarget Variable:\\n- AdoptionSpeed\\n\\nEach animalâ€™s adoption profile includes pictures, a text description, and various tabular features such as age, breed, name, color, and more. Letâ€™s look at a picture and description for an example row of data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:27,109 - \u001b[1mdescription\u001b[0m: data_description_file: Multimodal The goal is to predict pet adoption rates based on their adoption profiles. In this simplified version, the adoption speed is grouped into two categories: 0 (slow) and 1 (fast). \\n\\nTarget Variable:\\n- AdoptionSpeed\\n\\nEach animalâ€™s adoption profile includes pictures, a text description, and various tabular features such as age, breed, name, color, and more. Letâ€™s look at a picture and description for an example row of data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtrain_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:32,539 - \u001b[1mtrain_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtest_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:32,550 - \u001b[1mtest_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1msample_submission_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/sample_submission.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:32,553 - \u001b[1msample_submission_data\u001b[0m: /Users/aleksejlapin/Work/NEWFedotLLM/examples/multimodal/competition/petfinder_for_tutorial/sample_submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mlabel_column\u001b[0m: AdoptionSpeed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:33,936 - \u001b[1mlabel_column\u001b[0m: AdoptionSpeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mtask_type\u001b[0m: multimodal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:34,736 - \u001b[1mtask_type\u001b[0m: multimodal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1mproblem_type\u001b[0m: binary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,292 - \u001b[1mproblem_type\u001b[0m: binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.task_inference.task_inference:\u001b[1meval_metric\u001b[0m: f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,906 - \u001b[1meval_metric\u001b[0m: f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:\u001b[1mTotal number of prompt tokens:\u001b[0m 1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,908 - \u001b[1mTotal number of prompt tokens:\u001b[0m 1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:\u001b[1mTotal number of completion tokens:\u001b[0m 207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,910 - \u001b[1mTotal number of completion tokens:\u001b[0m 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Task understanding complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,912 - Task understanding complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.assistant:Automatic feature generation is disabled or not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,913 - Automatic feature generation is disabled or not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:It took 11.16 seconds preprocessing task. Time remaining: 588.77/600.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,914 - It took 11.16 seconds preprocessing task. Time remaining: 588.77/600.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model training starts<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model training starts\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.fedot:Found ['Description', 'PetID', 'Images'] text columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,939 - Found ['Description', 'PetID', 'Images'] text columns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.fedot:Found table features: 22.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,962 - Found table features: 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.fedot:Fitting Fedot TabularPredictor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,963 - Fitting Fedot TabularPredictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.fedot:predictor_init_kwargs: {'problem': 'classification', 'timeout': 9.81272049744924, 'metric': 'f1', 'preset': 'fast_train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,964 - predictor_init_kwargs: {'problem': 'classification', 'timeout': 9.81272049744924, 'metric': 'f1', 'preset': 'fast_train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fedotllm.predictor.fedot:predictor_fit_kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:28:35,964 - predictor_fit_kwargs: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - Initial pipeline was fitted in 12.1 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:02,958 - ApiComposer - Initial pipeline was fitted in 12.1 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - Taking into account n_folds=5, estimated fit time for initial assumption is 60.4 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:02,960 - ApiComposer - Taking into account n_folds=5, estimated fit time for initial assumption is 60.4 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - AutoML configured. Parameters tuning: True. Time limit: 9.81272049744924 min. Set of candidate models: ['bernb', 'dt', 'knn', 'logit', 'normalization', 'pca', 'qda', 'rf', 'scaling'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:02,966 - ApiComposer - AutoML configured. Parameters tuning: True. Time limit: 9.81272049744924 min. Set of candidate models: ['bernb', 'dt', 'knn', 'logit', 'normalization', 'pca', 'qda', 'rf', 'scaling'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:03,196 - ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [00:00<?, ?gen/s]/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Level 45:root:MultiprocessingDispatcher - 6 individuals out of 6 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:25,749 - MultiprocessingDispatcher - 6 individuals out of 6 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/aleksejlapin/Work/NEWFedotLLM/.venv/lib/python3.10/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Level 45:root:MultiprocessingDispatcher - 18 individuals out of 21 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:29:54,459 - MultiprocessingDispatcher - 18 individuals out of 21 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 13 individuals out of 15 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:30:17,836 - MultiprocessingDispatcher - 13 individuals out of 15 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 3 individuals out of 3 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:30:29,970 - MultiprocessingDispatcher - 3 individuals out of 3 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:30:53,631 - MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 1/10000 [01:50<306:43:41, 110.43s/gen]Level 45:root:MultiprocessingDispatcher - 17 individuals out of 17 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:31:28,630 - MultiprocessingDispatcher - 17 individuals out of 17 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 16 individuals out of 16 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:31:49,093 - MultiprocessingDispatcher - 16 individuals out of 16 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 2/10000 [02:45<216:53:49, 78.10s/gen] Level 45:root:MultiprocessingDispatcher - 34 individuals out of 34 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:32:22,875 - MultiprocessingDispatcher - 34 individuals out of 34 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 3/10000 [03:19<160:41:12, 57.86s/gen]Level 45:root:MultiprocessingDispatcher - 24 individuals out of 27 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:33:03,988 - MultiprocessingDispatcher - 24 individuals out of 27 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 20 individuals out of 23 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:33:58,823 - MultiprocessingDispatcher - 20 individuals out of 23 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 12 individuals out of 14 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:34:28,563 - MultiprocessingDispatcher - 12 individuals out of 14 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:MultiprocessingDispatcher - 37 individuals out of 37 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:34:28,596 - MultiprocessingDispatcher - 37 individuals out of 37 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 4/10000 [05:25<235:02:37, 84.65s/gen]Level 45:root:GroupedCondition - Optimisation stopped: Time limit is reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:34:28,664 - GroupedCondition - Optimisation stopped: Time limit is reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 4/10000 [05:25<225:55:30, 81.37s/gen]\n",
      "Level 45:root:ApiComposer - Hyperparameters tuning started with 4 min. timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:34:28,686 - ApiComposer - Hyperparameters tuning started with 4 min. timeout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:SimultaneousTuner - Initial graph: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 1, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 1, 'verbose': -1} \n",
      "Initial metric: [1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:36:17,104 - SimultaneousTuner - Initial graph: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 1, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 1, 'verbose': -1} \n",
      "Initial metric: [1.0]\n",
      "  0%|          | 66/100000 [02:23<60:27:19,  2.18s/trial, best loss: inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:SimultaneousTuner - Final graph: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 1, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 1, 'verbose': -1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:42,829 - SimultaneousTuner - Final graph: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 1, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 1, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 1, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 1, 'verbose': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:SimultaneousTuner - Final metric: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:42,831 - SimultaneousTuner - Final metric: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - Hyperparameters tuning finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:42,836 - ApiComposer - Hyperparameters tuning finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:ApiComposer - Model generation finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:43,017 - ApiComposer - Model generation finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:FEDOT logger - Final pipeline was fitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:58,885 - FEDOT logger - Final pipeline was fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 45:root:FEDOT logger - Final pipeline: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 12, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 12, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 12, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 12, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 12, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 12, 'verbose': -1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:38:58,887 - FEDOT logger - Final pipeline: {'depth': 5, 'length': 11, 'nodes': [rf, logit, catboost, data_source_table, xgboost, catboost, scaling, scaling, data_source_table, xgboost, lgbm]}\n",
      "rf - {'n_jobs': 12, 'criterion': 'gini', 'max_features': 0.6133633991973116, 'min_samples_split': 8, 'min_samples_leaf': 13, 'bootstrap': False}\n",
      "logit - {}\n",
      "catboost - {'n_jobs': 12, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 12, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "catboost - {'n_jobs': 12, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': False, 'allow_writing_files': False, 'use_eval_set': True, 'use_best_model': True, 'enable_categorical': True}\n",
      "scaling - {}\n",
      "scaling - {}\n",
      "data_source_table - {}\n",
      "xgboost - {'n_jobs': 12, 'verbosity': 0, 'booster': 'gbtree', 'tree_method': 'auto', 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30}\n",
      "lgbm - {'boosting_type': 'gbdt', 'max_depth': -1, 'bagging_fraction': 0.85, 'extra_trees': False, 'enable_categorical': True, 'use_eval_set': True, 'early_stopping_rounds': 30, 'n_jobs': 12, 'verbose': -1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Model training complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mModel training complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Prediction starts<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Prediction starts\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming: The following columns are not in predictions and will be treated as ID columns:['Id']\n",
      "Warming: Copied from test data for column 'Id'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Prediction complete! Outputs written to fedotllm-20250603_153900.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m Prediction complete! Outputs written to fedotllm-20250603_153900.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fedotllm-20250603_153900.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_assistant(\n",
    "    \"./competition/petfinder_for_tutorial\",\n",
    "    presets=\"medium_quality\",\n",
    "    config_overrides=[\"automl.enabled='fedot'\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
